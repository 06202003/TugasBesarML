{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "396103e7",
   "metadata": {},
   "source": [
    "<h1><center> Identifying Spam in Email Using Machine Learning </center></h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264cd9d4",
   "metadata": {},
   "source": [
    "# <a id=\"toc\">Table of Content</a>\n",
    "### 1. [Import Modul dan Persiapan Data](#)\n",
    "### 2. [Preprocessing Data](#)\n",
    "- 2.1. [Pengolahan Teks Email](#)\n",
    "- 2.2. [Stemming dan URL Extraction](#)\n",
    "- 2.3. [Transformasi Email menjadi Hitungan Kata](#)\n",
    "- 2.4. [Transformasi Hitungan Kata menjadi Representasi Vektor](#)\n",
    "### 3. [Model Klasifikasi dan Evaluasi](#)\n",
    "- 3.1. [Model Logistic Regression](#)\n",
    "- 3.2. [Model AdaBoost](#)\n",
    "- 3.3. [Model Support Vector Classifier (SVC)](#)\n",
    "- 3.4. [Model Random Forest](#)\n",
    "- 3.5. [Ensemble Voting Classifier.](#)\n",
    "### 4. [Contoh Penggunaan Model pada Data Uji](#)\n",
    "### 5. [Contoh Pembuatan Objek Email](#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5a4bc4",
   "metadata": {},
   "source": [
    "### Mengimport beberapa library yang digunakan. \n",
    "> Library seperti pandas, numpy, matplotlib, seaborn, os, tarfile, urllib.request, email, re, Counter, Pipeline, dan beberapa kelas dari sklearn diimpor untuk digunakan dalam program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfa83164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.svm import SVC\n",
    "from html import unescape\n",
    "import urllib.request\n",
    "import seaborn as sns\n",
    "import email.message\n",
    "import pandas as pd\n",
    "import email.policy\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import email\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac984d7",
   "metadata": {},
   "source": [
    "### Membaca file \"spam.csv\" menggunakan pd.read_csv dari library pandas. \n",
    "> Data tersebut disimpan dalam variabel sms. Lalu, nama kolomnya diubah menjadi 'label' dan 'message' menggunakan sms.columns = ['label', 'message']. sms.head() digunakan untuk menampilkan 5 baris pertama dari data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7adb1b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [label, message]\n",
       "Index: []"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms = pd.read_csv(\"spam.csv\",encoding='latin-1')\n",
    "sms.columns = ['label', 'message']\n",
    "\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec2c541",
   "metadata": {},
   "source": [
    "### Mendefinisikan fungsi fetch_spam_data() untuk mengunduh dataset spam. \n",
    "> Fungsi ini menggunakan URL untuk mengunduh file .tar.bz2 dari server dan mengekstraknya ke direktori yang ditentukan oleh spam_path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e0f277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_ROOT = \"http://spamassassin.apache.org/old/publiccorpus/\"\n",
    "HAM_URL = DOWNLOAD_ROOT + \"20030228_easy_ham.tar.bz2\"\n",
    "SPAM_URL = DOWNLOAD_ROOT + \"20030228_spam.tar.bz2\"\n",
    "SPAM_PATH = os.path.join(\"datasets\", \"spam\")\n",
    "\n",
    "def fetch_spam_data(ham_url=HAM_URL, spam_url=SPAM_URL, spam_path=SPAM_PATH):\n",
    "    if not os.path.isdir(spam_path):\n",
    "        os.makedirs(spam_path)\n",
    "    for filename, url in ((\"ham.tar.bz2\", ham_url), (\"spam.tar.bz2\", spam_url)):\n",
    "        path = os.path.join(spam_path, filename)\n",
    "        if not os.path.isfile(path):\n",
    "            urllib.request.urlretrieve(url, path)\n",
    "        tar_bz2_file = tarfile.open(path)\n",
    "        tar_bz2_file.extractall(path=spam_path)\n",
    "        tar_bz2_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "996f7a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_spam_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64106378",
   "metadata": {},
   "source": [
    "### Mendefinisikan direktori untuk email ham dan spam (HAM_DIR dan SPAM_DIR). \n",
    "> daftar nama file dalam direktori tersebut disimpan dalam variabel ham_filenames dan spam_filenames, dengan kondisi bahwa panjang nama file harus lebih dari 20 karakter. Jumlah file spam dan ham kemudian ditampilkan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cefbc596",
   "metadata": {},
   "outputs": [],
   "source": [
    "HAM_DIR = os.path.join(SPAM_PATH, \"easy_ham\")\n",
    "SPAM_DIR = os.path.join(SPAM_PATH, \"spam\")\n",
    "ham_filenames = [name for name in sorted(os.listdir(HAM_DIR)) if len(name) > 20]\n",
    "spam_filenames = [name for name in sorted(os.listdir(SPAM_DIR)) if len(name) > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b805a932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 2500)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spam_filenames), len(ham_filenames), "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f32704",
   "metadata": {},
   "source": [
    "### Mendefinisikan fungsi load_email() untuk membaca file email dalam format byte. \n",
    "> Fungsi ini menerima parameter is_spam untuk menentukan apakah email tersebut spam atau bukan, dan filename untuk menentukan nama file email yang akan dibaca. File email dibuka dalam mode byte dan di-parse menggunakan email.parser.BytesParser. Hasilnya disimpan dalam daftar ham_emails dan spam_emails, dan kemudian email pertama dari daftar ham_emails ditampilkan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2ec87e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_email(is_spam, filename, spam_path=SPAM_PATH):\n",
    "    directory = \"spam\" if is_spam else \"easy_ham\"\n",
    "    with open(os.path.join(spam_path, directory, filename), \"rb\") as f:\n",
    "        return email.parser.BytesParser(policy=email.policy.default).parse(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e40870c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<email.message.EmailMessage at 0x27a12fd4fd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_emails = [load_email(is_spam=False, filename=name) for name in ham_filenames]\n",
    "spam_emails = [load_email(is_spam=True, filename=name) for name in spam_filenames]\n",
    "ham_emails[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c948362",
   "metadata": {},
   "source": [
    "### Mencetak isi konten dari email ham ke-3 dan email spam ke-6. \n",
    "> .get_content() digunakan untuk mendapatkan konten email, dan .strip() digunakan untuk menghapus spasi yang tidak perlu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79b9f7f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Man Threatens Explosion In Moscow \n",
      "\n",
      "Thursday August 22, 2002 1:40 PM\n",
      "MOSCOW (AP) - Security officers on Thursday seized an unidentified man who\n",
      "said he was armed with explosives and threatened to blow up his truck in\n",
      "front of Russia's Federal Security Services headquarters in Moscow, NTV\n",
      "television reported.\n",
      "The officers seized an automatic rifle the man was carrying, then the man\n",
      "got out of the truck and was taken into custody, NTV said. No other details\n",
      "were immediately available.\n",
      "The man had demanded talks with high government officials, the Interfax and\n",
      "ITAR-Tass news agencies said. Ekho Moskvy radio reported that he wanted to\n",
      "talk with Russian President Vladimir Putin.\n",
      "Police and security forces rushed to the Security Service building, within\n",
      "blocks of the Kremlin, Red Square and the Bolshoi Ballet, and surrounded the\n",
      "man, who claimed to have one and a half tons of explosives, the news\n",
      "agencies said. Negotiations continued for about one and a half hours outside\n",
      "the building, ITAR-Tass and Interfax reported, citing witnesses.\n",
      "The man later drove away from the building, under police escort, and drove\n",
      "to a street near Moscow's Olympic Penta Hotel, where authorities held\n",
      "further negotiations with him, the Moscow police press service said. The\n",
      "move appeared to be an attempt by security services to get him to a more\n",
      "secure location. \n",
      "\n",
      "------------------------ Yahoo! Groups Sponsor ---------------------~-->\n",
      "4 DVDs Free +s&p Join Now\n",
      "http://us.click.yahoo.com/pt6YBB/NXiEAA/mG3HAA/7gSolB/TM\n",
      "---------------------------------------------------------------------~->\n",
      "\n",
      "To unsubscribe from this group, send an email to:\n",
      "forteana-unsubscribe@egroups.com\n",
      "\n",
      " \n",
      "\n",
      "Your use of Yahoo! Groups is subject to http://docs.yahoo.com/info/terms/\n"
     ]
    }
   ],
   "source": [
    "print(ham_emails[2].get_content().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fba03325",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A POWERHOUSE GIFTING PROGRAM You Don't Want To Miss! \n",
      " \n",
      "  GET IN WITH THE FOUNDERS! \n",
      "The MAJOR PLAYERS are on This ONE\n",
      "For ONCE be where the PlayerS are\n",
      "This is YOUR Private Invitation\n",
      "\n",
      "EXPERTS ARE CALLING THIS THE FASTEST WAY \n",
      "TO HUGE CASH FLOW EVER CONCEIVED\n",
      "Leverage $1,000 into $50,000 Over and Over Again\n",
      "\n",
      "THE QUESTION HERE IS:\n",
      "YOU EITHER WANT TO BE WEALTHY \n",
      "OR YOU DON'T!!!\n",
      "WHICH ONE ARE YOU?\n",
      "I am tossing you a financial lifeline and for your sake I \n",
      "Hope you GRAB onto it and hold on tight For the Ride of youR life!\n",
      "\n",
      "Testimonials\n",
      "\n",
      "Hear what average people are doing their first few days:\n",
      "�We've received 8,000 in 1 day and we are doing that over and over again!' Q.S. in AL\n",
      " �I'm a single mother in FL and I've received 12,000 in the last 4 days.� D. S. in FL\n",
      "�I was not sure about this when I sent off my $1,000 pledge, but I got back $2,000 the very next day!� L.L. in KY\n",
      "�I didn't have the money, so I found myself a partner to work this with. We have received $4,000 over the last 2 days. \n",
      "I think I made the right decision; don't you?� K. C. in FL\n",
      "�I pick up $3,000 my first day and I  they gave me free leads and all the training, you can too!� J.W. in CA\n",
      "\n",
      "ANNOUNCING: We will CLOSE your sales for YOU! And Help you get a Fax Blast IMMEDIATELY Upon Your Entry!!!    YOU Make the MONEY!!!\n",
      "FREE LEADS!!! TRAINING!!!\n",
      "\n",
      "$$DON'T WAIT!!! CALL NOW $$\n",
      "FAX BACK TO: 1-800-421-6318 OR Call 1-800-896-6568 \n",
      "\n",
      "Name__________________________________Phone___________________________________________\n",
      "\n",
      "Fax_____________________________________Email____________________________________________\n",
      "\n",
      "Best Time To Call_________________________Time Zone________________________________________\n",
      "\n",
      "This message is sent in compliance of the new e-mail bill. \"Per Section 301, Paragraph (a)(2)(C) of S. 1618, further transmissions by the sender of this email may be stopped, at no cost to you, by sending a reply to this email address with the word \"REMOVE\" in the subject line. Errors, omissions, and exceptions excluded.\n",
      " \n",
      "This is NOT spam! I have compiled this list from our Replicate Database, relative to Seattle Marketing Group, The Gigt, or Turbo Team for the sole purpose of these communications. Your continued inclusion is ONLY by your gracious permission. If you wish to not receive this mail from me, please send an email to tesrewinter@yahoo.com with \"Remove\" in the subject and you will be deleted immediately.\n"
     ]
    }
   ],
   "source": [
    "print(spam_emails[5].get_content().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de202cd7",
   "metadata": {},
   "source": [
    "### Mendefinisikan dua fungsi: get_email_structure() untuk mendapatkan struktur email dan structures_counter() untuk menghitung frekuensi struktur email. \n",
    "> Fungsi structures_counter() menghitung frekuensi struktur email pada daftar email ham dan spam. Hasilnya kemudian ditampilkan menggunakan .most_common() dari kelas Counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0390f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_structure(email):\n",
    "    if isinstance(email, str):\n",
    "        return email\n",
    "    payload = email.get_payload()\n",
    "    if isinstance(payload, list):\n",
    "        return \"multipart({})\".format(\", \".join([\n",
    "            get_email_structure(sub_email)\n",
    "            for sub_email in payload\n",
    "        ]))\n",
    "    else:\n",
    "        return email.get_content_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3967632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structures_counter(emails):\n",
    "    structures = Counter()\n",
    "    for email in emails:\n",
    "        structure = get_email_structure(email)\n",
    "        structures[structure] += 1\n",
    "    return structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4fcb08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text/plain', 2408),\n",
       " ('multipart(text/plain, application/pgp-signature)', 66),\n",
       " ('multipart(text/plain, text/html)', 8),\n",
       " ('multipart(text/plain, text/plain)', 4),\n",
       " ('multipart(text/plain)', 3),\n",
       " ('multipart(text/plain, application/octet-stream)', 2),\n",
       " ('multipart(text/plain, text/enriched)', 1),\n",
       " ('multipart(text/plain, application/ms-tnef, text/plain)', 1),\n",
       " ('multipart(multipart(text/plain, text/plain, text/plain), application/pgp-signature)',\n",
       "  1),\n",
       " ('multipart(text/plain, video/mng)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain))', 1),\n",
       " ('multipart(text/plain, application/x-pkcs7-signature)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), text/rfc822-headers)',\n",
       "  1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), multipart(multipart(text/plain, application/x-pkcs7-signature)))',\n",
       "  1),\n",
       " ('multipart(text/plain, application/x-java-applet)', 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures_counter(ham_emails).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df892982",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text/plain', 218),\n",
       " ('text/html', 183),\n",
       " ('multipart(text/plain, text/html)', 45),\n",
       " ('multipart(text/html)', 20),\n",
       " ('multipart(text/plain)', 19),\n",
       " ('multipart(multipart(text/html))', 5),\n",
       " ('multipart(text/plain, image/jpeg)', 3),\n",
       " ('multipart(text/html, application/octet-stream)', 2),\n",
       " ('multipart(text/plain, application/octet-stream)', 1),\n",
       " ('multipart(text/html, text/plain)', 1),\n",
       " ('multipart(multipart(text/html), application/octet-stream, image/jpeg)', 1),\n",
       " ('multipart(multipart(text/plain, text/html), image/gif)', 1),\n",
       " ('multipart/alternative', 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures_counter(spam_emails).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccc60f3",
   "metadata": {},
   "source": [
    "### Mencetak semua header dan nilainya dari email spam pertama dalam daftar spam_emails.\n",
    "> subjek dari email spam pertama juga dicetak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a6e437a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return-Path : <12a1mailbot1@web.de>\n",
      "Delivered-To : zzzz@localhost.spamassassin.taint.org\n",
      "Received : from localhost (localhost [127.0.0.1])\tby phobos.labs.spamassassin.taint.org (Postfix) with ESMTP id 136B943C32\tfor <zzzz@localhost>; Thu, 22 Aug 2002 08:17:21 -0400 (EDT)\n",
      "Received : from mail.webnote.net [193.120.211.219]\tby localhost with POP3 (fetchmail-5.9.0)\tfor zzzz@localhost (single-drop); Thu, 22 Aug 2002 13:17:21 +0100 (IST)\n",
      "Received : from dd_it7 ([210.97.77.167])\tby webnote.net (8.9.3/8.9.3) with ESMTP id NAA04623\tfor <zzzz@spamassassin.taint.org>; Thu, 22 Aug 2002 13:09:41 +0100\n",
      "From : 12a1mailbot1@web.de\n",
      "Received : from r-smtp.korea.com - 203.122.2.197 by dd_it7  with Microsoft SMTPSVC(5.5.1775.675.6);\t Sat, 24 Aug 2002 09:42:10 +0900\n",
      "To : dcek1a1@netsgo.com\n",
      "Subject : Life Insurance - Why Pay More?\n",
      "Date : Wed, 21 Aug 2002 20:31:57 -1600\n",
      "MIME-Version : 1.0\n",
      "Message-ID : <0103c1042001882DD_IT7@dd_it7>\n",
      "Content-Type : text/html; charset=\"iso-8859-1\"\n",
      "Content-Transfer-Encoding : quoted-printable\n"
     ]
    }
   ],
   "source": [
    "for header, value in spam_emails[0].items():\n",
    "    print(header,\":\",value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "960e6631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Life Insurance - Why Pay More?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_emails[0][\"Subject\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc49e9b9",
   "metadata": {},
   "source": [
    "### Menggabungkan email ham dan spam menjadi satu array X, dan labelnya disimpan dalam array y. \n",
    "> data dibagi menjadi data latih dan data uji menggunakan train_test_split() dengan proporsi 80:20. Variabel X_train, X_test, y_train, dan y_test akan berisi data yang telah dibagi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83c5996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(ham_emails + spam_emails, dtype=object)\n",
    "y = np.array([0] * len(ham_emails) + [1] * len(spam_emails))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5ccdc4",
   "metadata": {},
   "source": [
    "### Mendefinisikan fungsi html_to_plain_text() untuk mengkonversi teks dalam format HTML menjadi teks biasa. \n",
    "> Fungsi ini menggunakan ekspresi reguler untuk menghilangkan tag HTML dan menggantikan hyperlink dengan kata \"HYPERLINK\". Kemudian, unescape() digunakan untuk mengubah karakter khusus HTML menjadi karakter aslinya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ca402df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_to_plain_text(html):\n",
    "    text = re.sub('<head.*?>.*?</head>', '', html, flags=re.M | re.S | re.I)\n",
    "    text = re.sub('<a\\s.*?>', ' HYPERLINK ', text, flags=re.M | re.S | re.I)\n",
    "    text = re.sub('<.*?>', '', text, flags=re.M | re.S)\n",
    "    text = re.sub(r'(\\s*\\n)+', '\\n', text, flags=re.M | re.S)\n",
    "    return unescape(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c750cef3",
   "metadata": {},
   "source": [
    "### Mencari email spam dalam format HTML dalam data latih (X_train) dan menyimpannya dalam daftar html_spam_emails. \n",
    "> email spam HTML yang kedelapan dalam daftar tersebut dipilih dan kontennya dicetak, baik dalam format asli maupun dalam format teks biasa setelah diproses menggunakan html_to_plain_text()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "935f327e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HTML><HEAD><TITLE></TITLE><META http-equiv=\"Content-Type\" content=\"text/html; charset=windows-1252\"><STYLE>A:link {TEX-DECORATION: none}A:active {TEXT-DECORATION: none}A:visited {TEXT-DECORATION: none}A:hover {COLOR: #0033ff; TEXT-DECORATION: underline}</STYLE><META content=\"MSHTML 6.00.2713.1100\" name=\"GENERATOR\"></HEAD>\n",
      "<BODY text=\"#000000\" vLink=\"#0033ff\" link=\"#0033ff\" bgColor=\"#CCCC99\"><TABLE borderColor=\"#660000\" cellSpacing=\"0\" cellPadding=\"0\" border=\"0\" width=\"100%\"><TR><TD bgColor=\"#CCCC99\" valign=\"top\" colspan=\"2\" height=\"27\">\n",
      "<font size=\"6\" face=\"Arial, Helvetica, sans-serif\" color=\"#660000\">\n",
      "<b>OTC</b></font></TD></TR><TR><TD height=\"2\" bgcolor=\"#6a694f\">\n",
      "<font size=\"5\" face=\"Times New Roman, Times, serif\" color=\"#FFFFFF\">\n",
      "<b>&nbsp;Newsletter</b></font></TD><TD height=\"2\" bgcolor=\"#6a694f\"><div align=\"right\"><font color=\"#FFFFFF\">\n",
      "<b>Discover Tomorrow's Winners&nbsp;</b></font></div></TD></TR><TR><TD height=\"25\" colspan=\"2\" bgcolor=\"#CCCC99\"><table width=\"100%\" border=\"0\"  ...\n"
     ]
    }
   ],
   "source": [
    "html_spam_emails = [email for email in X_train[y_train==1]\n",
    "                    if get_email_structure(email) == \"text/html\"]\n",
    "sample_html_spam = html_spam_emails[7]\n",
    "print(sample_html_spam.get_content().strip()[:1000], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fae23c92",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OTC\n",
      " Newsletter\n",
      "Discover Tomorrow's Winners \n",
      "For Immediate Release\n",
      "Cal-Bay (Stock Symbol: CBYI)\n",
      "Watch for analyst \"Strong Buy Recommendations\" and several advisory newsletters picking CBYI.  CBYI has filed to be traded on the OTCBB, share prices historically INCREASE when companies get listed on this larger trading exchange. CBYI is trading around 25 cents and should skyrocket to $2.66 - $3.25 a share in the near future.\n",
      "Put CBYI on your watch list, acquire a position TODAY.\n",
      "REASONS TO INVEST IN CBYI\n",
      "A profitable company and is on track to beat ALL earnings estimates!\n",
      "One of the FASTEST growing distributors in environmental & safety equipment instruments.\n",
      "Excellent management team, several EXCLUSIVE contracts.  IMPRESSIVE client list including the U.S. Air Force, Anheuser-Busch, Chevron Refining and Mitsubishi Heavy Industries, GE-Energy & Environmental Research.\n",
      "RAPIDLY GROWING INDUSTRY\n",
      "Industry revenues exceed $900 million, estimates indicate that there could be as much as $25 billi ...\n"
     ]
    }
   ],
   "source": [
    "print(html_to_plain_text(sample_html_spam.get_content())[:1000], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376b4ee0",
   "metadata": {},
   "source": [
    "### Mendefinisikan fungsi email_to_text() untuk mengambil teks dari email. \n",
    "> Fungsi ini berjalan melalui setiap bagian email (part) dan mencari konten dengan tipe \"text/plain\" atau \"text/html\". Jika konten berupa teks biasa, maka konten tersebut dikembalikan. Jika konten berupa HTML, maka konten tersebut diubah menjadi teks biasa menggunakan html_to_plain_text(). Kemudian, potongan pertama dari teks hasil pengolahan tersebut dicetak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9002cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_to_text(email):\n",
    "    html = None\n",
    "    for part in email.walk():\n",
    "        ctype = part.get_content_type()\n",
    "        if not ctype in (\"text/plain\", \"text/html\"):\n",
    "            continue\n",
    "        try:\n",
    "            content = part.get_content()\n",
    "        except: # in case of encoding issues\n",
    "            content = str(part.get_payload())\n",
    "        if ctype == \"text/plain\":\n",
    "            return content\n",
    "        else:\n",
    "            html = content\n",
    "    if html:\n",
    "        return html_to_plain_text(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fd1ad89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OTC\n",
      " Newsletter\n",
      "Discover Tomorrow's Winners \n",
      "For Immediate Release\n",
      "Cal-Bay (Stock Symbol: CBYI)\n",
      "Wat ...\n"
     ]
    }
   ],
   "source": [
    "print(email_to_text(sample_html_spam)[:100], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63e98c2",
   "metadata": {},
   "source": [
    "### Mengimpor library nltk dan urlextract. \n",
    "> Sebelum menggunakan library-library tersebut, perlu dilakukan instalasi terlebih dahulu menggunakan nltk.download() untuk library NLTK dan pip install urlextract untuk library urlextract. Jika library belum diinstal, maka pesan kesalahan akan ditampilkan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9b2ac87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computations => comput\n",
      "Computation => comput\n",
      "Computing => comput\n",
      "Computed => comput\n",
      "Compute => comput\n",
      "Compulsive => compuls\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import nltk\n",
    "\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    for word in (\"Computations\", \"Computation\", \"Computing\", \"Computed\", \"Compute\", \"Compulsive\"):\n",
    "        print(word, \"=>\", stemmer.stem(word))\n",
    "except ImportError:\n",
    "    print(\"Error: stemming requires the NLTK module.\")\n",
    "    stemmer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4eb2e5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: replacing URLs requires the urlextract module.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import urlextract # may require an Internet connection to download root domain names\n",
    "    \n",
    "    url_extractor = urlextract.URLExtract()\n",
    "    print(url_extractor.find_urls(\"Will it detect github.com and https://youtu.be/7Pq-S557XQU?t=3m32s\"))\n",
    "except ImportError:\n",
    "    print(\"Error: replacing URLs requires the urlextract module.\")\n",
    "    url_extractor = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3b1e80",
   "metadata": {},
   "source": [
    "### Mendefinisikan kelas EmailToWordCounterTransformer yang merupakan subclass dari BaseEstimator dan TransformerMixin dari modul scikit-learn. \n",
    "> Kelas ini bertujuan untuk mentransformasi email menjadi hitungan kata. Konstruktor kelas ini menerima beberapa argumen opsional yang mengatur pemrosesan teks seperti penghapusan header, lowercase, penghapusan tanda baca, penggantian URL, penggantian angka, dan stemming.\n",
    "\n",
    "> Metode fit tidak melakukan apapun, hanya mengembalikan dirinya sendiri. Metode transform melakukan transformasi email menjadi hitungan kata dengan menerapkan pemrosesan teks yang telah diatur sebelumnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a28e9707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class EmailToWordCounterTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strip_headers=True, lower_case=True, remove_punctuation=True,\n",
    "                 replace_urls=True, replace_numbers=True, stemming=True):\n",
    "        self.strip_headers = strip_headers\n",
    "        self.lower_case = lower_case\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.replace_urls = replace_urls\n",
    "        self.replace_numbers = replace_numbers\n",
    "        self.stemming = stemming\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        for email in X:\n",
    "            text = email_to_text(email) or \"\"\n",
    "            if self.lower_case:\n",
    "                text = text.lower()\n",
    "            if self.replace_urls and url_extractor is not None:\n",
    "                urls = list(set(url_extractor.find_urls(text)))\n",
    "                urls.sort(key=lambda url: len(url), reverse=True)\n",
    "                for url in urls:\n",
    "                    text = text.replace(url, \" URL \")\n",
    "            if self.replace_numbers:\n",
    "                text = re.sub(r'\\d+(?:\\.\\d*)?(?:[eE][+-]?\\d+)?', 'NUMBER', text)\n",
    "            if self.remove_punctuation:\n",
    "                text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
    "            word_counts = Counter(text.split())\n",
    "            if self.stemming and stemmer is not None:\n",
    "                stemmed_word_counts = Counter()\n",
    "                for word, count in word_counts.items():\n",
    "                    stemmed_word = stemmer.stem(word)\n",
    "                    stemmed_word_counts[stemmed_word] += count\n",
    "                word_counts = stemmed_word_counts\n",
    "            X_transformed.append(word_counts)\n",
    "        return np.array(X_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77ad4cf",
   "metadata": {},
   "source": [
    "### Menginisialisasi objek EmailToWordCounterTransformer dan menerapkan transformasi pada tiga email pertama dalam X_train. Hasil transformasi berupa hitungan kata akan ditampilkan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a9c0caf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Counter({'chuck': 1, 'murcko': 1, 'wrote': 1, 'stuff': 1, 'yawn': 1, 'r': 1}),\n",
       "       Counter({'the': 11, 'of': 9, 'and': 8, 'all': 3, 'christian': 3, 'to': 3, 'by': 3, 'jefferson': 2, 'i': 2, 'have': 2, 'superstit': 2, 'one': 2, 'on': 2, 'been': 2, 'ha': 2, 'half': 2, 'rogueri': 2, 'teach': 2, 'jesu': 2, 'some': 1, 'interest': 1, 'quot': 1, 'http': 1, 'www': 1, 'postfun': 1, 'com': 1, 'pfp': 1, 'worboi': 1, 'html': 1, 'thoma': 1, 'examin': 1, 'known': 1, 'word': 1, 'do': 1, 'not': 1, 'find': 1, 'in': 1, 'our': 1, 'particular': 1, 'redeem': 1, 'featur': 1, 'they': 1, 'are': 1, 'alik': 1, 'found': 1, 'fabl': 1, 'mytholog': 1, 'million': 1, 'innoc': 1, 'men': 1, 'women': 1, 'children': 1, 'sinc': 1, 'introduct': 1, 'burnt': 1, 'tortur': 1, 'fine': 1, 'imprison': 1, 'what': 1, 'effect': 1, 'thi': 1, 'coercion': 1, 'make': 1, 'world': 1, 'fool': 1, 'other': 1, 'hypocrit': 1, 'support': 1, 'error': 1, 'over': 1, 'earth': 1, 'six': 1, 'histor': 1, 'american': 1, 'john': 1, 'e': 1, 'remsburg': 1, 'letter': 1, 'william': 1, 'short': 1, 'again': 1, 'becom': 1, 'most': 1, 'pervert': 1, 'system': 1, 'that': 1, 'ever': 1, 'shone': 1, 'man': 1, 'absurd': 1, 'untruth': 1, 'were': 1, 'perpetr': 1, 'upon': 1, 'a': 1, 'larg': 1, 'band': 1, 'dupe': 1, 'import': 1, 'led': 1, 'paul': 1, 'first': 1, 'great': 1, 'corrupt': 1}),\n",
       "       Counter({'number': 5, 'http': 4, 'yahoo': 4, 's': 3, 'group': 3, 'com': 3, 'to': 3, 'in': 2, 'forteana': 2, 'martin': 2, 'an': 2, 'and': 2, 'memri': 2, 'we': 2, 'is': 2, 'unsubscrib': 2, 'y': 1, 'adamson': 1, 'wrote': 1, 'for': 1, 'altern': 1, 'rather': 1, 'more': 1, 'factual': 1, 'base': 1, 'rundown': 1, 'on': 1, 'hamza': 1, 'career': 1, 'includ': 1, 'hi': 1, 'belief': 1, 'that': 1, 'all': 1, 'non': 1, 'muslim': 1, 'yemen': 1, 'should': 1, 'be': 1, 'murder': 1, 'outright': 1, 'org': 1, 'bin': 1, 'articl': 1, 'cgi': 1, 'page': 1, 'archiv': 1, 'area': 1, 'ia': 1, 'id': 1, 'ianumb': 1, 'know': 1, 'how': 1, 'unbias': 1, 'don': 1, 't': 1, 'www': 1, 'guardian': 1, 'co': 1, 'uk': 1, 'elsewher': 1, 'journalist': 1, 'stori': 1, 'html': 1, 'rob': 1, 'sponsor': 1, 'dvd': 1, 'free': 1, 'p': 1, 'join': 1, 'now': 1, 'us': 1, 'click': 1, 'ptnumberybb': 1, 'nxieaa': 1, 'mvfiaa': 1, 'numbergsolb': 1, 'tm': 1, 'from': 1, 'thi': 1, 'send': 1, 'email': 1, 'egroup': 1, 'your': 1, 'use': 1, 'of': 1, 'subject': 1, 'doc': 1, 'info': 1, 'term': 1})],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_few = X_train[:3]\n",
    "X_few_wordcounts = EmailToWordCounterTransformer().fit_transform(X_few)\n",
    "X_few_wordcounts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8820854e",
   "metadata": {},
   "source": [
    "### Mendefinisikan kelas WordCounterToVectorTransformer yang juga merupakan subclass dari BaseEstimator dan TransformerMixin dari modul scikit-learn. \n",
    "> Kelas ini bertujuan untuk mentransformasi hitungan kata menjadi representasi vektor. Konstruktor kelas ini menerima argumen opsional vocabulary_size yang menentukan ukuran vokabulari yang digunakan.\n",
    "\n",
    "> Metode fit melakukan perhitungan frekuensi kata pada data masukan X dan menghasilkan kamus vokabulari berdasarkan kata-kata dengan frekuensi tertinggi. Metode transform melakukan transformasi hitungan kata menjadi representasi vektor berdasarkan kamus vokabulari yang telah diperoleh sebelumnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "581fef7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordCounterToVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vocabulary_size=1000):\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "    def fit(self, X, y=None):\n",
    "        total_count = Counter()\n",
    "        for word_count in X:\n",
    "            for word, count in word_count.items():\n",
    "                total_count[word] += min(count, 10)\n",
    "        most_common = total_count.most_common()[:self.vocabulary_size]\n",
    "        self.vocabulary_ = {word: index + 1 for index, (word, count) in enumerate(most_common)}\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        data = []\n",
    "        for row, word_count in enumerate(X):\n",
    "            for word, count in word_count.items():\n",
    "                rows.append(row)\n",
    "                cols.append(self.vocabulary_.get(word, 0))\n",
    "                data.append(count)\n",
    "        return csr_matrix((data, (rows, cols)), shape=(len(X), self.vocabulary_size + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ba7fe0",
   "metadata": {},
   "source": [
    "### Menginisialisasi objek WordCounterToVectorTransformer dengan ukuran vokabulari sebesar 10 dan menerapkan transformasi pada hitungan kata yang diperoleh sebelumnya (X_few_wordcounts). \n",
    "> Hasil transformasi berupa representasi vektor akan ditampilkan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a041797c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x11 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 20 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transformer = WordCounterToVectorTransformer(vocabulary_size=10)\n",
    "X_few_vectors = vocab_transformer.fit_transform(X_few_wordcounts)\n",
    "X_few_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38513989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [112,  11,   9,   8,   3,   1,   0,   1,   3,   0,   1],\n",
       "       [ 92,   0,   1,   2,   3,   4,   5,   3,   1,   4,   2]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_few_vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "637c4840",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'of': 2,\n",
       " 'and': 3,\n",
       " 'to': 4,\n",
       " 'http': 5,\n",
       " 'number': 6,\n",
       " 'com': 7,\n",
       " 'all': 8,\n",
       " 'yahoo': 9,\n",
       " 'in': 10}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transformer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e4552a",
   "metadata": {},
   "source": [
    "### Menggunakan Pipeline dari scikit-learn untuk menggabungkan dua transformer sebelumnya menjadi sebuah pipeline yang dapat digunakan untuk melakukan transformasi secara berurutan.\n",
    "> preprocess_pipeline terdiri dari dua langkah transformasi: \n",
    "> 1. EmailToWordCounterTransformer.\n",
    "> 2. WordCounterToVectorTransformer. \n",
    "\n",
    "> Pipeline ini kemudian digunakan untuk mentransformasi X_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f50547f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_pipeline = Pipeline([\n",
    "    (\"email_to_wordcount\", EmailToWordCounterTransformer()),\n",
    "    (\"wordcount_to_vector\", WordCounterToVectorTransformer()),\n",
    "])\n",
    "\n",
    "X_train_transformed = preprocess_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dd31d2",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1752898",
   "metadata": {},
   "source": [
    "### Menginisialisasi model klasifikasi LogisticRegression dari scikit-learn dan melakukan evaluasi menggunakan cross-validation dengan 3 fold pada data transformasi (X_train_transformed) dan label (y_train). \n",
    "> Akurasi rata-rata dari cross-validation akan ditampilkan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf5634a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.983) total time=   0.0s\n",
      "[CV] END ................................ score: (test=0.985) total time=   0.0s\n",
      "[CV] END ................................ score: (test=0.993) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9866666666666667"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = LogisticRegression(solver=\"lbfgs\", max_iter=1000, random_state=42)\n",
    "score = cross_val_score(log_clf, X_train_transformed, y_train, cv=3, verbose=3)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a63faca",
   "metadata": {},
   "source": [
    "### Melakukan transformasi pada data uji (X_test) menggunakan pipeline yang telah di-fit sebelumnya. \n",
    "> Model LogisticRegression dilatih menggunakan data transformasi latih (X_train_transformed) dan label latih (y_train). Prediksi dilakukan pada data transformasi uji dan kemudian ditampilkan nilai presisi dan recall dari hasil prediksi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ccc2f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 95.88%\n",
      "Recall: 97.89%\n"
     ]
    }
   ],
   "source": [
    "X_test_transformed = preprocess_pipeline.transform(X_test)\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\", max_iter=1000, random_state=42)\n",
    "log_clf.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred = log_clf.predict(X_test_transformed)\n",
    "\n",
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred)))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd04302f",
   "metadata": {},
   "source": [
    "### Mengulangi langkah-langkah yang sama seperti sebelumnya, namun menggunakan model klasifikasi yang berbeda seperti AdaBoostClassifier, SVC (Support Vector Classifier), dan RandomForestClassifier. Hasil presisi dan recall dari setiap model juga ditampilkan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fb25f8",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "573ea70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.980) total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.986) total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.985) total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98375"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed = preprocess_pipeline.fit_transform(X_train)\n",
    "\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "score_adaboost = cross_val_score(ada_clf, X_train_transformed, y_train, cv=3, verbose=3)\n",
    "score_adaboost.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e1415d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 96.94%\n",
      "Recall: 100.00%\n"
     ]
    }
   ],
   "source": [
    "X_test_transformed = preprocess_pipeline.transform(X_test)\n",
    "\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "ada_clf.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred_adaboost = ada_clf.predict(X_test_transformed)\n",
    "\n",
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred_adaboost)))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred_adaboost)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439822e3",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91b05fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.948) total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.954) total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.951) total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9508333333333333"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed = preprocess_pipeline.fit_transform(X_train)\n",
    "\n",
    "svc_clf = SVC(gamma='auto')\n",
    "score_svc = cross_val_score(svc_clf, X_train_transformed, y_train, cv=3, verbose=3)\n",
    "score_svc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef1d4cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 100.00%\n",
      "Recall: 75.79%\n"
     ]
    }
   ],
   "source": [
    "X_test_transformed = preprocess_pipeline.transform(X_test)\n",
    "\n",
    "svc_clf = SVC(gamma='auto')\n",
    "svc_clf.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred_svc = svc_clf.predict(X_test_transformed)\n",
    "\n",
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred_svc)))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred_svc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394374fc",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5556e452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.983) total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.986) total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.985) total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9845833333333333"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed = preprocess_pipeline.fit_transform(X_train)\n",
    "\n",
    "ran_clf = RandomForestClassifier(random_state=42)\n",
    "score_randfor = cross_val_score(ran_clf, X_train_transformed, y_train, cv=3, verbose=3)\n",
    "score_randfor.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f479da53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 98.84%\n",
      "Recall: 89.47%\n"
     ]
    }
   ],
   "source": [
    "X_test_transformed = preprocess_pipeline.transform(X_test)\n",
    "\n",
    "ran_clf = RandomForestClassifier(random_state=42)\n",
    "ran_clf.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred_randfor = ran_clf.predict(X_test_transformed)\n",
    "\n",
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred_randfor)))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred_randfor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b1cbd59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<email.message.EmailMessage object at 0x0000027A18304250>,\n",
       "       <email.message.EmailMessage object at 0x0000027A18304F70>,\n",
       "       <email.message.EmailMessage object at 0x0000027A12FD70D0>, ...,\n",
       "       <email.message.EmailMessage object at 0x0000027A1970E0E0>,\n",
       "       <email.message.EmailMessage object at 0x0000027A199A5030>,\n",
       "       <email.message.EmailMessage object at 0x0000027A18306AA0>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "add0b3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<600x1001 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 51594 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ce2b5b",
   "metadata": {},
   "source": [
    "# Ensemble Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ddd5a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_clf = RandomForestClassifier(random_state=42)\n",
    "lg_reg            = LogisticRegression(solver=\"lbfgs\", max_iter=1000, random_state=42)\n",
    "svm_clf           = SVC(gamma='auto')\n",
    "ada_clf           = AdaBoostClassifier(n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5563744",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    random_forest_clf, \n",
    "    lg_reg, \n",
    "    svm_clf, \n",
    "    ada_clf\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05a27b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the RandomForestClassifier(random_state=42)\n",
      "Training the LogisticRegression(max_iter=1000, random_state=42)\n",
      "Training the SVC(gamma='auto')\n",
      "Training the AdaBoostClassifier(n_estimators=100, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "for estimator in estimators:\n",
    "    print(\"Training the\", estimator)\n",
    "    estimator.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b47da4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision RandomForestClassifier(random_state=42) : 98.84%\n",
      "Recall  RandomForestClassifier(random_state=42) : 89.47%\n",
      "\n",
      "Precision LogisticRegression(max_iter=1000, random_state=42) : 95.88%\n",
      "Recall  LogisticRegression(max_iter=1000, random_state=42) : 97.89%\n",
      "\n",
      "Precision SVC(gamma='auto') : 100.00%\n",
      "Recall  SVC(gamma='auto') : 75.79%\n",
      "\n",
      "Precision AdaBoostClassifier(n_estimators=100, random_state=42) : 96.94%\n",
      "Recall  AdaBoostClassifier(n_estimators=100, random_state=42) : 100.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for estimator in estimators:\n",
    "    print(\"Precision \"+str(estimator)+\" : {:.2f}%\".format(100 * precision_score(y_test, estimator.predict(X_test_transformed) )))\n",
    "    print(\"Recall  \"+str(estimator)+\" : {:.2f}%\".format(100 * recall_score(y_test, estimator.predict(X_test_transformed) )))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7da3a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "named_estimators = [\n",
    "    (\"random_forest_clf\", random_forest_clf),\n",
    "    (\"logistic_regression\", lg_reg),\n",
    "    (\"svm_clf\", svm_clf),\n",
    "    (\"adaboost_clf\", ada_clf),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7281a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(named_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a0941a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;random_forest_clf&#x27;,\n",
       "                              RandomForestClassifier(random_state=42)),\n",
       "                             (&#x27;logistic_regression&#x27;,\n",
       "                              LogisticRegression(max_iter=1000,\n",
       "                                                 random_state=42)),\n",
       "                             (&#x27;svm_clf&#x27;, SVC(gamma=&#x27;auto&#x27;)),\n",
       "                             (&#x27;adaboost_clf&#x27;,\n",
       "                              AdaBoostClassifier(n_estimators=100,\n",
       "                                                 random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;random_forest_clf&#x27;,\n",
       "                              RandomForestClassifier(random_state=42)),\n",
       "                             (&#x27;logistic_regression&#x27;,\n",
       "                              LogisticRegression(max_iter=1000,\n",
       "                                                 random_state=42)),\n",
       "                             (&#x27;svm_clf&#x27;, SVC(gamma=&#x27;auto&#x27;)),\n",
       "                             (&#x27;adaboost_clf&#x27;,\n",
       "                              AdaBoostClassifier(n_estimators=100,\n",
       "                                                 random_state=42))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>random_forest_clf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>logistic_regression</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>svm_clf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(gamma=&#x27;auto&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>adaboost_clf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(n_estimators=100, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('random_forest_clf',\n",
       "                              RandomForestClassifier(random_state=42)),\n",
       "                             ('logistic_regression',\n",
       "                              LogisticRegression(max_iter=1000,\n",
       "                                                 random_state=42)),\n",
       "                             ('svm_clf', SVC(gamma='auto')),\n",
       "                             ('adaboost_clf',\n",
       "                              AdaBoostClassifier(n_estimators=100,\n",
       "                                                 random_state=42))])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce7e3a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<600x1001 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 51594 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0021a87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_votingpred = voting_clf.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6585a592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 100.00%\n",
      "Recall: 93.68%\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_votingpred)))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_votingpred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40124969",
   "metadata": {},
   "source": [
    "### Mendefinisikan fungsi create_email yang digunakan untuk membuat objek email menggunakan modul email bawaan Python. \n",
    "> Objek email ini kemudian digunakan sebagai contoh data untuk diuji menggunakan pipeline yang telah dibangun sebelumnya. Hasilnya adalah list test yang berisi objek email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a23c897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_email(sender, recipient, subject, message):\n",
    "    email_msg = email.message.EmailMessage()\n",
    "    email_msg['From'] = sender\n",
    "    email_msg['To'] = recipient\n",
    "    email_msg['Subject'] = subject\n",
    "    email_msg.set_content(message)\n",
    "\n",
    "    return email_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "002370bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<email.message.EmailMessage at 0x27a1cc56380>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sender = 'spammer@example.com'\n",
    "recipient = 'yehezkiel@example.com'\n",
    "subject = 'Life Insurance - Why Pay More?'\n",
    "message = \"Watch for analyst 'Strong Buy Recommendations' and several advisory newsletters picking CBYI.  CBYI has filed to be traded on the OTCBB, share prices historically INCREASE when companies get listed on this larger trading exchange. CBYI is trading around 25 cents and should skyrocket to $2.66 - $3.25 a share in the near future. Put CBYI on your watch list, acquire a position TODAY.\"\n",
    "\n",
    "email_obj = create_email(sender, recipient, subject, message)\n",
    "test = [email_obj]\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc932e8",
   "metadata": {},
   "source": [
    "<h1><center> The End </center></h1> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
